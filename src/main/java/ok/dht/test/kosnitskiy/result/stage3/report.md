ENVIRONMENT-DESCRIPTION
Тестирование производилось на 6-ядерном, 6-поточном процессоре. 
Были запущены 3 ноды, для распределения нагрузки между ними было решено использовать murmur алгоритм хеширования,
так как из протестированных мной он предложил самое адекватное распределение информации по нодам.

GET-DESCRIPTION
Для тестирования было решено использовать ключи, закрытые сверху еще 1.5 гигами информации с другими ключами. 
Это стандартный юзкейс для нашей базы данных - ключи существуют, однако чтобы их достать прийдется порыться по файлам
и выкопать их их глубины

PUT-DESCRIPTION
Для PUT мы генерировали разные ключи, чтобы гарантировать, что размер DAO будет увеличиваться и не будет
перезаписываться одно и тоже значение кучу раз.
Так же мы стали генерировать строки разной длинны чтобы несколько усложить бинарный поиск по получившимся файлам

WRK-PUT
◆ utils git:(stage3) ✗ ❯❯❯ wrk -d 20s -t 4 -c 64 -R 7000 -s put-different.lua --latency "http://localhost:19230"
Running 20s test @ http://localhost:19230
4 threads and 64 connections
Thread calibration: mean lat.: 4.633ms, rate sampling interval: 20ms
Thread calibration: mean lat.: 4.618ms, rate sampling interval: 20ms
Thread calibration: mean lat.: 4.554ms, rate sampling interval: 20ms
Thread calibration: mean lat.: 6.975ms, rate sampling interval: 26ms
Thread Stats   Avg      Stdev     Max   +/- Stdev
Latency     5.14ms    3.90ms  31.76ms   77.87%
Req/Sec     1.79k   299.57     2.89k    69.65%
Latency Distribution (HdrHistogram - Recorded Latency)
50.000%    4.16ms
75.000%    6.87ms
90.000%   10.31ms
99.000%   18.50ms
99.900%   26.78ms
99.990%   29.79ms
99.999%   31.63ms
100.000%   31.77ms

Тестирование производилось при нагрузке node 0
Легко заметить, что наша скорость добавления данных в базу упала сразу в 10 раз, этого следовало ожидать, учитывая
что раньше задачка положить что-то в базу была легкой, а теперь ноде приходится не только высчитывать хеш у каждого
из ключей, что довольно неприятная операция, так еще и потенциально идти в другую ноду и ждать ответа об успешном
положении ключа из нее.
Тут главное улучшение которое можно сделать в данный момент - это алгоритм хождения от одной ноды к другой, во-первых
http - точно не самое быстрое решение, которое не особо рационально использовать в нашем случае, но мы делаем это
ради скорости, во-вторых хорошо бы было написать алгоритм, который бы смотрел, что к нам не просто пришел запрос,
а запрос от нашей ноды - товарища, и в таком случае не считать хеш и не делать никаких доп проверок, а сразу класть
ключ в базу, так будет намного быстрее. Сейчас же хеш высчитывается два раза и мы не различаем себя от чужого.
Так же различие 50 с даже 90 перцентилями стало намного сильнее, это связано с тем, что теперь у нас намного больше
долгих запросов и они встречаются не только в 99 перцентиле - это запросы, которые ходят в другую ноду
Так же падение производительности связано с тем, что все наши ноды работают на одной машине



WRK-GET
◆ utils git:(stage3) ✗ ❯❯❯ wrk -d 20s -t 4 -c 64 -R 4000 -s get-random.lua --latency "http://localhost:19230"
Running 20s test @ http://localhost:19230
4 threads and 64 connections
Thread calibration: mean lat.: 2.509ms, rate sampling interval: 10ms
Thread calibration: mean lat.: 2.479ms, rate sampling interval: 10ms
Thread calibration: mean lat.: 2.459ms, rate sampling interval: 10ms
Thread calibration: mean lat.: 2.451ms, rate sampling interval: 10ms
Thread Stats   Avg      Stdev     Max   +/- Stdev
Latency     2.06ms    1.52ms  17.25ms   83.24%
Req/Sec     1.05k   192.46     2.00k    80.42%
Latency Distribution (HdrHistogram - Recorded Latency)
50.000%    1.64ms
75.000%    2.46ms
90.000%    3.92ms
99.000%    7.74ms
99.900%   11.36ms
99.990%   15.08ms
99.999%   17.26ms
100.000%   17.26ms


Для гета с учетом того, что потеря произоводительности связана с запуском всех 3 нод на одной машине почти незаметна.
Это связано с тем, что в гете мы не только проигрываем в скорости как в путе(по тем же причинам), но еще и существенно
выигрываем. Дело в том, что теперь файлов на каждой ноде намного меньше, ведь теперь они распределены по 3 нодам, а
до этого ютились на одной. Это дает нам большое преимущество!

Спасибо за прочтение!