# Отчет по 3 стадии

!!!!!!!!!! Такие низкие показатели ордеррейта потому что рабочий антивирус eset при нагрузке начинает резко сжирать 60-70% cpu.

Была взята rockDB реализация базы данных. И до начала тестирования нагружена данными примерно на 15.6GB суммарно на 3 узла

Несмотря на все трудности с async-profiler, я почти смог его победить. Подебажив async-profiler получилось 
заставить его работать на wsl, теперь в отчетах будет хитмапа, но с профилированием локов все еще проблемы. При 
конвертации в html из jfr, jrf2flame отказывается конвертировать локи, хотя информация о них собиралась во время
профилирования.

По сравнению с прошлым этапом, было добавлено шардирование кластера на несколько нод.
После ресолва реквеста в сервис и проверки запроса на минимальную корректность 
с помощью NodeRouters(использующего Jumping hashes в сочетании с Hash.murmur3, отличающейся максимально честным 
распределением по нодам и возможность добавления нод(но не удаления)
по ключу вычисляется подходящая нода для переадресовки запроса.

Кроме того был реализован circuit breaker(так что дайте бонус!!!), использующий Scheduled thread pool.
При обнаружении дисконекта ноды, все запросы на нее начинают реджектится и создается таска раз в 5 секунд
мониторящая доступность ноды, которая открывает доступ к ней при подъеме.

В отчете будут отражены результаты подачи нагрузки через первую ноду, но за кадром была протестирована
нагрузка на все ноды. 

Кроме того, стоит отметить, что из-за подхода использующегося в предыдущем дз с распараллеливанием на уровне
сервера и нежелание нарушать все возможные принципы инкапсуляции с выполнение работы сервиса в сервере,
не было возможность добавить отдельный тредпул для асинхронного редиректа запросов, и редирект происходит
в основном тредпуле для записи данных(что на самом деле не особо и проблема то).

Стоит отметить, что неочевидной причиной дергадации перформанса мог быть переезд на wsl(в профайлинге очевидно мы это не увидим,
но я подозреваю что накладные расходы все таки присутствуют)

Более очевидными проблемами деградации перформанса являются: 
1. Возросшая в 3 раза нагрузка на ресурсы компьютера(ноды то локально поднимаются). А если бы поднимались не локально,
сеть бы передала привет(хотя про нее дальше).
2. Возросшая сетевая нагрузка мастер узла. Отправка и прием редеректнутого запроса на другой узел совсем 
не бесплатная. По сути мы почти в 2/3 раза сильнее нагружаем сеть узла.
3. Использование circuit breaker тоже не дается бесплатно(нам все еще нужен тредпул для мониторинга доступности нод),
хоть и дает куда больше импакта, из-за того, что мы не тратим время на попытки отправки заведомо мертвых запросов,
а сразу их реджектим.


Далее я приведу результаты профилирования с минимальными комментариями по возможным улучшениям(писать пасту
про то у кого сколько процентов не вижу смысла, это очевидно видно из флейм графа).
   
[//]: # (# Профилирование)

[//]: # (## PUT)

[//]: # (### Latency&#40;wrk2&#41;)

[//]: # (Ордеррейт 6000 оказался стабильной нагрузкой, при которой 99 процентов запросов укладывается в 12 мс, при нагрузке 6500)

[//]: # (99 персентиль возрастает до 462 мс.)

[//]: # (По сравнения с однопоточной реализаций, ордеррейд возрос в 6 раз, что при 8 физический потоках является неплохим результатом.)

[//]: # (Put все еще выдерживает больший ордеррейт из-за особенностей структуры данных в бд)

[//]: # (```)

[//]: # ()
[//]: # (```)

[//]: # ()
[//]: # (### Flame graph)

[//]: # (#### Cpu)

[//]: # (Различия с однопоточной версией не то чтобы колоссальные. Изменилась иерархия вызова по пути к конченым функциям &#40;теперь)

[//]: # (selectorThread отвечает только за прием данных, а тредпул за занесение в бд и отправку ответа&#41;, а соотношение используемового)

[//]: # (cpu осталось примерно таким же. Стоит отметить разве что появление ThreadPoolExecutor.getTask занимающей 4% и отвественной)

[//]: # (за менеджмент тасок в тредпуле.)

[//]: # (![put_cpu_merged]&#40;put_cpu_merged.png&#41;)

[//]: # ()
[//]: # (#### Alloc)

[//]: # ()
[//]: # (Ситуация не сильно изменилась по сравнения с однопоточным приложением. Вот общая картина по тредам. И дальше посмотрим детали.)

[//]: # (Из общей картины можно сделать вывод что почти все аллокации так же уходят на прием объектов из сети как и в 1 поточном случае)

[//]: # (![put_alloc_merged]&#40;put_alloc_merged.png&#41;)

[//]: # ()
[//]: # ()
[//]: # (Для селектора ситуация выглядит так. 98% уходит на processRead. Неудивительно, ведь мы разделили функционал так,)

[//]: # (что селектор треды только читают поступающие запросы, а записью ответов и выполнение бизнес логики занимаются уже воркеры.)

[//]: # ()
[//]: # (![put_alloc_selector]&#40;put_alloc_selector.png&#41;)

[//]: # ()
[//]: # (Для воркера ситуация уже интереснее. 6% уходит на внутренние аллокации для Executor. 25% уходит на Request.getPararmeter и)

[//]: # (Request.getPath &#40;внутрениие функции one.nio омогающие в роутинге&#41;. И самое главное 41% на запись ответа по сети sendResponse)

[//]: # (и 27% на саму запись в бд.)

[//]: # ()
[//]: # (![put_alloc_worker]&#40;put_alloc_worker.png&#41;)

[//]: # ()
[//]: # (#### Lock)

[//]: # ()
[//]: # (90% на LinkBlockQueue.take - ожидание доступа к очереди внутри тредпула&#40;потенциально можно лок фри структуру юзать&#41;  и)

[//]: # (10 % на ожидание разрешения для взаимодействия с сокетом.)

[//]: # ()
[//]: # (![put_lock_worker]&#40;put_lock_merged.png&#41;)

[//]: # ()
[//]: # ()
[//]: # ()
[//]: # (# GET)

[//]: # (### Latency&#40;wrk2&#41;)

[//]: # (Ордеррейт 5000 является стабильным, при котором 99% запросов обрабатывается за 4 мс. При ордеррейте 6000 задержки уже порядка 2000)

[//]: # (Нагрузка так же как и для put выросла в ~6 раз.)

[//]: # ()
[//]: # (```)

[//]: # (```)

[//]: # (### Flame graph)

[//]: # (Глобальные отличия от однопоточной программы описаны в пут секции.)

[//]: # ()
[//]: # (#### Cpu)

[//]: # (Изменения описанные в секции про put так же актуальны и для get. 4% на getTask в тред пуде. И разнесение чтения-селекта и обработки-записи)

[//]: # (запроса по разным тредам. Проценты каждой из секций равносильны процентам в однопоточном приложении. Единственное можно отметить)

[//]: # (что взятие из бд и запись ответа оказались в одном потоке, что оптимально для пут, но плохо для гет&#40;две самые затратные оперции)

[//]: # (в 1 потоке&#41;. В итоге у нас трейд офф или быстрый гет или быстрый пут. Выбираем пут:&#41;)

[//]: # ()
[//]: # (![get_cpu_merged]&#40;get_cpu_merged.png&#41;)

[//]: # ()
[//]: # (#### Alloc)

[//]: # (Все так же похоже на однопоточную программу. 47% writeResponse, 46% getEntity и какие-то копейки на getTask и селект.)

[//]: # (![get_alloc_merged]&#40;get_alloc_merged.png&#41;)

[//]: # ()
[//]: # (#### Lock)

[//]: # ()
[//]: # (![get_lock_merged]&#40;get_lock_merged.png&#41;)

[//]: # ()
[//]: # (Все так же 90% на LinkBlockQueue.take - ожидание доступа к очереди внутри тредпула&#40;потенциально можно лок фри структуру юзать&#41;  и)

[//]: # (10 % на ожидание разрешения для взаимодействия с сокетом.)

[//]: # ()
[//]: # ()
[//]: # ()
